{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07380f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>margin</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>82b9ca49aa8b92fd1cf0963b52fb1734eda3232303c669...</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>71.39</td>\n",
       "      <td>21.42</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>42586e958c1c38c359654b9f2e9384a3c76377619fed4d...</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>47.19</td>\n",
       "      <td>14.16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>42586e958c1c38c359654b9f2e9384a3c76377619fed4d...</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>49.39</td>\n",
       "      <td>14.82</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             product_id        date  \\\n",
       "1626  82b9ca49aa8b92fd1cf0963b52fb1734eda3232303c669...  2019-03-20   \n",
       "2130  42586e958c1c38c359654b9f2e9384a3c76377619fed4d...  2019-06-15   \n",
       "3134  42586e958c1c38c359654b9f2e9384a3c76377619fed4d...  2020-07-23   \n",
       "\n",
       "      sell_price  margin  sales  \n",
       "1626       71.39   21.42     17  \n",
       "2130       47.19   14.16      8  \n",
       "3134       49.39   14.82     15  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize_scalar\n",
    "import support_functions as sf\n",
    "import importlib, support_functions, inspect\n",
    "importlib.reload(support_functions)\n",
    "# print('module file:', support_functions.__file__)\n",
    "# print(inspect.getsource(support_functions.change_product_name)[:400])\n",
    "# from pygam import glm, s, f, te, PoissonGAM, ExponentialGAM, ExpectileGAM\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "path = Path(\"data\") / \"ml_task_data.csv\"\n",
    "raw_data = pd.read_csv(path)\n",
    "raw_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5659cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id\n",
       "58fba35ac3591d27507b733ea4a6dc1c8b1c2cf04ddbbd6b3d4a4da3a3c8fd3c    755\n",
       "b2141f3341478ce4ee74781f7da95dcbc3ee6d9a5309659d5163026415e98bb9    739\n",
       "82b9ca49aa8b92fd1cf0963b52fb1734eda3232303c669d02f2537ecdcbd8314    737\n",
       "42586e958c1c38c359654b9f2e9384a3c76377619fed4d958949c0305e25b85c    677\n",
       "56154e85b0dacaa9d34e280f4470e0dd2db370c22d98ec775c7d2fd6827eba5c    645\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess data\n",
    "df = support_functions.create_date_time_index(raw_data)\n",
    "# quick check of products\n",
    "df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd84073",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id\n",
       "product_A    755\n",
       "product_B    739\n",
       "product_C    737\n",
       "product_D    677\n",
       "product_E    645\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = support_functions.change_product_name(df)\n",
    "df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b2a859",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_product_A, df_product_B, df_product_C, df_product_D, df_product_E = support_functions.createProductDataFrames(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4072c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'change_column_names' from 'support_functions' (/home/sumit/repos/forecasting/Rohlik/support_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msupport_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m change_column_names\n\u001b[32m      4\u001b[39m df_product_A =change_column_names(df_product_A, \u001b[33m'\u001b[39m\u001b[33mA\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m df_product_B =change_column_names(df_product_B, \u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'change_column_names' from 'support_functions' (/home/sumit/repos/forecasting/Rohlik/support_functions.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from support_functions import change_column_names\n",
    "\n",
    "\n",
    "df_product_A =change_column_names(df_product_A, 'A')\n",
    "df_product_B =change_column_names(df_product_B, 'B')\n",
    "df_product_C =change_column_names(df_product_C, 'C')\n",
    "df_product_D =change_column_names(df_product_D, 'D')\n",
    "df_product_E =change_column_names(df_product_E, 'E')\n",
    "# Show the first rows and columns to confirm\n",
    "df_product_A.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_product_A.merge(df_product_B, left_index=True, right_index=True, how='outer') \\\n",
    "              .merge(df_product_C, left_index=True, right_index=True, how='outer') \\\n",
    "                  .merge(df_product_D, left_index=True, right_index=True, how='outer') \\\n",
    "                      .merge(df_product_E, left_index=True, right_index=True, how='outer')\n",
    "                      \n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432db7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = create_temporal_features(df_merge)\n",
    "# df_merge.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93862ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot of log_sell_price and log_sales for all products\n",
    "corr_cols = [col for col in df_merge.columns if ('log_sell_price' in col) or ('log_sales' in col)]\n",
    "price_corr = df_merge[corr_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(price_corr, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, ax=ax, cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title('Correlation Matrix: Log Sell Prices and Log Sales (All Products)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Log Sell Price and Log Sales Correlations:')\n",
    "print(price_corr.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0cdac",
   "metadata": {},
   "source": [
    "# OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_statsmodels(fdf, product ='A',other_products_flag = False  ,temporal_columns_flag=False):\n",
    "    \"\"\"\n",
    "    Perform OLS regression using statsmodels to predict log_sales_{product} from df_model.\n",
    "    \"\"\"\n",
    "    temporal_col_names = [ 'dayofmonth', 'month', 'year','is_weekend'] #'dayofweek',\n",
    "    # 'dayofyear' and 'month' are correlated - exclude 'dayofyear'\n",
    "    col_name_product = [f'log_sales_{product}']\n",
    "    col_name_product_price = [f'log_sell_price_{product}']\n",
    "    col_names_price = [ 'log_sell_price_A','log_sell_price_B','log_sell_price_C','log_sell_price_D','log_sell_price_E']\n",
    "    if other_products_flag == False:\n",
    "        col_names_price = col_name_product_price\n",
    "    if temporal_columns_flag == False:\n",
    "        temporal_col_names = []\n",
    "    df_model = fdf[col_name_product+col_names_price+temporal_col_names].copy(deep=True)\n",
    "    print(f\"Running OLS regression for product: {product}\")\n",
    "    print(\"-\"*70)\n",
    "    print(df_model.columns.tolist())\n",
    "    # Use df_model\n",
    "    df_work = df_model.copy(deep=True)\n",
    "\n",
    "    target = f'log_sales_{product}'\n",
    "    if target not in df_work.columns:\n",
    "        raise KeyError(f\"{target} not found in df_model columns: {df_work.columns.tolist()}\")\n",
    "\n",
    "    # Select numeric features (exclude target)\n",
    "    X = df_work.select_dtypes(include=[\"number\"]).drop(columns=[target], errors='ignore')\n",
    "    y = df_work[target]\n",
    "\n",
    "    # Drop rows with NaNs\n",
    "    mask = X.notna().all(axis=1) & y.notna()\n",
    "    X = X.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "\n",
    "    # Remove constant columns\n",
    "    X = X.loc[:, X.std() > 0]\n",
    "\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Number of observations: {len(y)}\")\n",
    "    print(f\"Features ({len(X.columns)}): {X.columns.tolist()}\")\n",
    "\n",
    "    # Fit OLS\n",
    "    X_sm = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_sm)\n",
    "    results = model.fit()\n",
    "    beta0, beta1 = results.params[0], results.params[1]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STATSMODELS OLS REGRESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(results.summary())\n",
    "\n",
    "    # Store results\n",
    "    _sm_ols_results = results\n",
    "    \n",
    "    return _sm_ols_results, beta0, beta1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = linear_regression_statsmodels(df_merge, product ='A')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defa8b2",
   "metadata": {},
   "source": [
    "We have used **power-law demand function:**\n",
    "$$ ln(q) = \\beta_0 + \\beta_1 ln(p) $$\n",
    "$$ q(p) = e^{\\beta_0} e^{\\beta_1 ln(p)} = e^{\\beta_0} e^{ln(p^{\\beta_1})} = e^{\\beta_0} p^{\\beta1} $$\n",
    "$$R(p) = p \\times q(p) = e^{\\beta_0} \\times p^{\\beta_1 + 1}$$\n",
    "Using FOC (to maximize revenue):\n",
    "$$\\frac{dR}{dp} = 0 \\implies \\frac{e^{\\beta_0} \\times p^{\\beta_1 + 1}}{dp} = 0$$\n",
    "$$\\implies \\beta_1 = -1$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e570bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_merge[['sell_price_A','sales_A','log_sales_A','log_sell_price_A']].copy(deep=True)\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        'sell_price_A':'price','sales_A':'sales',\n",
    "        'log_sell_price_A':'ln_price','log_sales_A':'ln_sales'\n",
    "        }\n",
    "    )\n",
    "print(data.shape)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "# Fit log–log regression\n",
    "X = sm.add_constant(data['ln_price'])\n",
    "model = sm.OLS(data['ln_sales'], X).fit()\n",
    "beta0, beta1 = model.params\n",
    "\n",
    "print(\"Regression coefficients:\")\n",
    "print(f\"β0 = {beta0:.4f}, β1 = {beta1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand function\n",
    "def demand(p):\n",
    "    return np.exp(beta0) * p**beta1\n",
    "\n",
    "# Revenue function\n",
    "def revenue(p):\n",
    "    return p * demand(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec30580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maximize revenue numerically within a sensible range\n",
    "res = minimize_scalar(lambda p: -revenue(p),\n",
    "                      bounds=(min(data['price']), max(data['price'])*5),\n",
    "                      method='bounded')\n",
    "\n",
    "optimal_price = res.x\n",
    "max_revenue = revenue(optimal_price)\n",
    "\n",
    "print(f\"Optimal price: {optimal_price:.2f}\")\n",
    "print(f\"Max revenue: {max_revenue:.2f}\")\n",
    "print(f\"Sales: {max_revenue/optimal_price:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a1f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_statsmodels(df_merge, product ='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_statsmodels(df_merge, product ='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_statsmodels(df_merge, product ='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ec832",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_statsmodels(df_merge, product ='E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean regression workflow: impute, scale, Lasso feature selection, sklearn LR, and statsmodels OLS\n",
    "# # Requires: scikit-learn, statsmodels (already installed)\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LassoCV, LinearRegression\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# # Use merged dataframe\n",
    "# df_work = df_model.copy()\n",
    "\n",
    "# target = 'log_sales_A'\n",
    "# if target not in df_work.columns:\n",
    "#     raise KeyError(f\"{target} not found in df_merge columns: {df_work.columns.tolist()}\")\n",
    "\n",
    "# # Select numeric features (exclude target)\n",
    "# X_raw = df_work.select_dtypes(include=[\"number\"]).drop(columns=[target], errors='ignore')\n",
    "# y = df_work[target]\n",
    "\n",
    "# # Align and drop rows where target is missing\n",
    "# mask = y.notna()\n",
    "# X_raw = X_raw.loc[mask]\n",
    "# y = y.loc[mask]\n",
    "\n",
    "# # Impute median for numeric features\n",
    "# imp = SimpleImputer(strategy='median')\n",
    "# X_imp = pd.DataFrame(imp.fit_transform(X_raw), index=X_raw.index, columns=X_raw.columns)\n",
    "\n",
    "# # Remove constant columns\n",
    "# stds = X_imp.std()\n",
    "# non_const_cols = stds[stds > 0].index.tolist()\n",
    "# X_imp = X_imp[non_const_cols]\n",
    "\n",
    "# # Scale\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = pd.DataFrame(scaler.fit_transform(X_imp), index=X_imp.index, columns=X_imp.columns)\n",
    "\n",
    "# # LassoCV for feature selection (use default 5-fold CV)\n",
    "# lasso = LassoCV(n_alphas=100, cv=5, random_state=42, max_iter=5000)\n",
    "# lasso.fit(X_scaled, y.loc[X_scaled.index])\n",
    "# selector = SelectFromModel(lasso, prefit=True, threshold='median')\n",
    "# selected_mask = selector.get_support()\n",
    "# selected_features = X_scaled.columns[selected_mask].tolist()\n",
    "\n",
    "# print('Selected features ({}):'.format(len(selected_features)))\n",
    "# print(selected_features)\n",
    "\n",
    "# if len(selected_features) == 0:\n",
    "#     print('No features selected by Lasso; using top 10 by absolute coef')\n",
    "#     coef_series = pd.Series(np.abs(lasso.coef_), index=X_scaled.columns)\n",
    "#     selected_features = list(coef_series.sort_values(ascending=False).head(10).index)\n",
    "\n",
    "# X_sel = X_scaled[selected_features]\n",
    "\n",
    "# # Train/test evaluation with sklearn LinearRegression\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_sel, y.loc[X_sel.index], test_size=0.2, random_state=42)\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "# y_pred = lr.predict(X_test)\n",
    "# print('\\nSklearn LinearRegression R^2 on test set:', r2_score(y_test, y_pred))\n",
    "\n",
    "# # Show top coefficients\n",
    "# coefs = pd.Series(lr.coef_, index=selected_features)\n",
    "# print('\\nTop coefficients (sklearn LR):')\n",
    "# print(coefs.sort_values(key=lambda s: s.abs(), ascending=False).head(20))\n",
    "\n",
    "# # Statsmodels OLS on selected features (full data without scaling inverse is fine for inference here)\n",
    "# # Rebuild X for statsmodels using original (imputed but not scaled) values for interpretability\n",
    "# X_sm = X_imp[selected_features]\n",
    "# X_sm = sm.add_constant(X_sm)\n",
    "# model = sm.OLS(y.loc[X_sm.index], X_sm)\n",
    "# results = model.fit()\n",
    "# print('\\nOLS summary:')\n",
    "# print(results.summary())\n",
    "\n",
    "# # Store results objects for later inspection\n",
    "# _regression_results = {\n",
    "#     'selected_features': selected_features,\n",
    "#     'sklearn_lr': lr,\n",
    "#     'lasso_model': lasso,\n",
    "#     'statsmodels_results': results\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b073ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_price_sales(fdf, product_name):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    print(\"Here\")\n",
    "\n",
    "    # Plot sales over time\n",
    "    axes[0].plot(fdf.index, fdf[f'log_sales_{product_name}'], marker='o', linestyle='-', linewidth=2)\n",
    "    axes[0].set_title(f'{product_name} - Log Sales Over Time', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Date')\n",
    "    axes[0].set_ylabel('Log Sales')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot sell_price over time\n",
    "    axes[1].plot(fdf.index, fdf[f'log_sell_price_{product_name}'], marker='s', linestyle='-', linewidth=2, color='orange')\n",
    "    axes[1].set_title(f'{product_name} - Log Sell Price Over Time', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Log Sell Price')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b03100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_sales(df_merge, 'A')\n",
    "# plot_price_sales(df_merge, 'B')\n",
    "# plot_price_sales(df_merge, 'C')\n",
    "# plot_price_sales(df_merge, 'D')\n",
    "plot_price_sales(df_merge, 'E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaceb2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21970775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_sales_correlation(df_product, product_name):\n",
    "    # Correlation plot between sell_price and sales\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.scatter(df_product['log_price'], df_product['log_sales'], alpha=0.6, s=50, color='steelblue')\n",
    "    ax.set_xlabel('Log Sell Price', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Log Sales', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{product_name} - Correlation between Log Sell Price and Log Sales', fontsize=13, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add correlation coefficient\n",
    "    corr = df_product['log_price'].corr(df_product['log_sales'])\n",
    "    ax.text(0.05, 0.95, f'Correlation: {corr:.3f}', transform=ax.transAxes, \n",
    "            fontsize=11, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot_price_sales_correlation(df_product_A, 'Product A')\n",
    "# plot_price_sales_correlation(df_product_B, 'Product B')\n",
    "# plot_price_sales_correlation(df_product_C, 'Product C')\n",
    "# plot_price_sales_correlation(df_product_D, 'Product D')\n",
    "plot_price_sales_correlation(df_product_E, 'Product E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Day-wise boxplot of sales\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# products = [df_product_A, df_product_B, df_product_C, df_product_D, df_product_E]\n",
    "# product_names = ['Product A', 'Product B', 'Product C', 'Product D', 'Product E']\n",
    "# days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# for idx, (df_product, product_name) in enumerate(zip(products, product_names)):\n",
    "#     # Prepare data for boxplot\n",
    "#     data_by_day = [df_product[df_product['dayofweek'] == day]['sales'].values for day in range(7)]\n",
    "    \n",
    "#     bp = axes[idx].boxplot(data_by_day, labels=days, patch_artist=True)\n",
    "    \n",
    "#     # Color the boxes\n",
    "#     for patch in bp['boxes']:\n",
    "#         patch.set_facecolor('lightblue')\n",
    "    \n",
    "#     axes[idx].set_title(f'{product_name} - Day-wise Sales Distribution', fontsize=11, fontweight='bold')\n",
    "#     axes[idx].set_xlabel('Day of Week')\n",
    "#     axes[idx].set_ylabel('Sales')\n",
    "#     axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Hide the extra subplot\n",
    "# axes[5].set_visible(False)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f09837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Day-wise boxplot of sell_price\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# products = [df_product_A, df_product_B, df_product_C, df_product_D, df_product_E]\n",
    "# product_names = ['Product A', 'Product B', 'Product C', 'Product D', 'Product E']\n",
    "# days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "# for idx, (df_product, product_name) in enumerate(zip(products, product_names)):\n",
    "#     # Prepare data for boxplot\n",
    "#     data_by_day = [df_product[df_product['dayofweek'] == day]['sell_price'].values for day in range(7)]\n",
    "    \n",
    "#     bp = axes[idx].boxplot(data_by_day, labels=days, patch_artist=True)\n",
    "    \n",
    "#     # Color the boxes\n",
    "#     for patch in bp['boxes']:\n",
    "#         patch.set_facecolor('lightcoral')\n",
    "    \n",
    "#     axes[idx].set_title(f'{product_name} - Day-wise Price Distribution', fontsize=11, fontweight='bold')\n",
    "#     axes[idx].set_xlabel('Day of Week')\n",
    "#     axes[idx].set_ylabel('Sell Price')\n",
    "#     axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# # Hide the extra subplot\n",
    "# axes[5].set_visible(False)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add45ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Requirements: statsmodels, scikit-learn\n",
    "# # pip install statsmodels scikit-learn\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Replace with your merged dataframe variable if different\n",
    "# df_work = df_merge.copy()\n",
    "\n",
    "# target = 'log_sales_A'   # dependent variable\n",
    "# if target not in df_work.columns:\n",
    "#     raise KeyError(f\"{target} not found in dataframe columns: {df_work.columns.tolist()}\")\n",
    "\n",
    "# # Build X: numeric columns except the target\n",
    "# X = df_work.select_dtypes(include=[np.number]).drop(columns=[target], errors='ignore')\n",
    "# y = df_work[target]\n",
    "\n",
    "# # Drop rows with NaNs in X or y\n",
    "# mask = X.notna().all(axis=1) & y.notna()\n",
    "# X = X.loc[mask]\n",
    "# y = y.loc[mask]\n",
    "\n",
    "# # (Optional) remove perfectly collinear or constant columns\n",
    "# X = X.loc[:, X.std() > 0]\n",
    "\n",
    "# # --- OLS (statsmodels) ---\n",
    "# X_sm = sm.add_constant(X)         # adds intercept term\n",
    "# model = sm.OLS(y, X_sm)\n",
    "# results = model.fit()\n",
    "# print(\"OLS summary:\")\n",
    "# print(results.summary())\n",
    "\n",
    "# # --- Train/test linear regression (scikit-learn) ---\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "# y_pred = lr.predict(X_test)\n",
    "# print(\"\\nSklearn LinearRegression R^2 on test set:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# # Show coefficients (aligned to feature names)\n",
    "# coefs = pd.Series(lr.coef_, index=X.columns)\n",
    "# print(\"\\nCoefficients (sklearn LR):\")\n",
    "# print(coefs.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edf8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compact regression summary, save full OLS to file, and run CV (R^2 and MAE)\n",
    "# from pathlib import Path\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# out_dir = Path('results')\n",
    "# out_dir.mkdir(exist_ok=True)\n",
    "# summary_path = out_dir / 'regression_summary.txt'\n",
    "\n",
    "# # Retrieve stored results\n",
    "# res = globals().get('_regression_results', None)\n",
    "# if res is None:\n",
    "#     raise RuntimeError(\"_regression_results not found. Run the regression cell first.\")\n",
    "\n",
    "# selected_features = res.get('selected_features', [])\n",
    "# lr = res.get('sklearn_lr')\n",
    "# lasso = res.get('lasso_model')\n",
    "# sm_res = res.get('statsmodels_results')\n",
    "\n",
    "# # Compact print\n",
    "# print('Selected features ({}):'.format(len(selected_features)))\n",
    "# print(selected_features)\n",
    "\n",
    "# # Top coefficients from sklearn LR\n",
    "# if lr is not None:\n",
    "#     coefs = pd.Series(lr.coef_, index=selected_features)\n",
    "#     print('\\nTop coefficients (sklearn LR):')\n",
    "#     print(coefs.sort_values(key=lambda s: s.abs(), ascending=False).head(10))\n",
    "# else:\n",
    "#     print('\\nNo sklearn LR model found in _regression_results')\n",
    "\n",
    "# # Test R^2: try to compute if test split stored (not stored). We'll recompute a quick train/test split for a compact R^2.\n",
    "# try:\n",
    "#     X_imp = globals().get('X_imp')\n",
    "#     y = globals().get('y')\n",
    "#     if X_imp is None or y is None:\n",
    "#         # try to rebuild minimal X_imp,y from df_merge\n",
    "#         df_work = globals().get('df_merge')\n",
    "#         if df_work is None:\n",
    "#             raise RuntimeError('df_merge not found for recomputing test R^2')\n",
    "#         # use selected features from df_merge (impute median)\n",
    "#         X_temp = df_work[selected_features].copy()\n",
    "#         X_temp = X_temp.fillna(X_temp.median())\n",
    "#         y_temp = df_work['log_sales_A'].loc[X_temp.index]\n",
    "#     else:\n",
    "#         X_temp = X_imp[selected_features].copy()\n",
    "#         y_temp = y.loc[X_temp.index]\n",
    "\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "#     lr_tmp = LinearRegression()\n",
    "#     lr_tmp.fit(X_train, y_train)\n",
    "#     y_pred = lr_tmp.predict(X_test)\n",
    "#     test_r2 = r2_score(y_test, y_pred)\n",
    "#     print(f\"\\nCompact test R^2 (recomputed): {test_r2:.4f}\")\n",
    "# except Exception as e:\n",
    "#     print('\\nCould not recompute compact test R^2:', e)\n",
    "\n",
    "# # Cross-validated scores\n",
    "# try:\n",
    "#     X_cv = X_temp\n",
    "#     y_cv = y_temp\n",
    "#     # R^2 CV\n",
    "#     cv_r2 = cross_val_score(LinearRegression(), X_cv, y_cv, cv=5, scoring='r2')\n",
    "#     # MAE CV (negative MAE returned by scikit-learn with scoring that expects higher is better)\n",
    "#     neg_mae = cross_val_score(LinearRegression(), X_cv, y_cv, cv=5, scoring='neg_mean_absolute_error')\n",
    "#     cv_mae = -neg_mae\n",
    "#     print(f\"\\nCV R^2 (5-fold): mean={cv_r2.mean():.4f}, std={cv_r2.std():.4f}\")\n",
    "#     print(f\"CV MAE (5-fold): mean={cv_mae.mean():.4f}, std={cv_mae.std():.4f}\")\n",
    "# except Exception as e:\n",
    "#     print('\\nCV evaluation failed:', e)\n",
    "\n",
    "# # Save full OLS summary to file\n",
    "# try:\n",
    "#     with open(summary_path, 'w') as f:\n",
    "#         f.write('Selected features:\\n')\n",
    "#         f.write('\\n'.join(selected_features) + '\\n\\n')\n",
    "#         f.write('Sklearn coefficients (top 50):\\n')\n",
    "#         if lr is not None:\n",
    "#             coef_lines = coefs.sort_values(key=lambda s: s.abs(), ascending=False).head(50).to_string()\n",
    "#             f.write(coef_lines + '\\n\\n')\n",
    "#         f.write('Statsmodels OLS summary:\\n')\n",
    "#         if sm_res is not None:\n",
    "#             f.write(str(sm_res.summary()) + '\\n')\n",
    "#         else:\n",
    "#             f.write('No statsmodels results found')\n",
    "#     print(f\"\\nFull OLS summary saved to {summary_path}\")\n",
    "# except Exception as e:\n",
    "#     print('\\nFailed to write summary file:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b205f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multicollinearity check: correlation pairs, VIF, and condition number\n",
    "# from pathlib import Path\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# product = 'A'\n",
    "# temporal_col_names =['dayofweek', 'dayofmonth','dayofyear', 'month', 'year','is_weekend']\n",
    "# col_name_product = [f'log_sales_{product}']\n",
    "# col_names_price = [ 'log_sell_price_A','log_sell_price_B','log_sell_price_C','log_sell_price_D','log_sell_price_E']\n",
    "# df_model = df_merge[col_name_product+col_names_price+temporal_col_names].copy(deep=True)\n",
    "# out_dir = Path('results')\n",
    "# out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# # Choose working dataframe: df_model (as built earlier)\n",
    "# df_work = globals().get('df_model', None)\n",
    "# if df_work is None:\n",
    "#     raise RuntimeError('df_model not found in notebook namespace')\n",
    "\n",
    "# # target may be log_sales_A — exclude target from features\n",
    "# target = f'log_sales_{product}'\n",
    "# if target in df_work.columns:\n",
    "#     X = df_work.drop(columns=[target])\n",
    "# else:\n",
    "#     X = df_work.copy()\n",
    "\n",
    "# # Keep numeric columns only\n",
    "# X_num = X.select_dtypes(include=[np.number]).copy()\n",
    "# if X_num.shape[1] == 0:\n",
    "#     raise RuntimeError('No numeric features found to compute multicollinearity')\n",
    "\n",
    "# # Impute median for any missing values to allow VIF computation\n",
    "# imp = SimpleImputer(strategy='median')\n",
    "# X_imp = pd.DataFrame(imp.fit_transform(X_num), index=X_num.index, columns=X_num.columns)\n",
    "\n",
    "# # Compute correlation matrix and list high-correlation pairs\n",
    "# corr = X_imp.corr()\n",
    "# threshold = 0.8\n",
    "# high_pairs = []\n",
    "# cols = X_imp.columns.tolist()\n",
    "# for i in range(len(cols)):\n",
    "#     for j in range(i+1, len(cols)):\n",
    "#         v = corr.iloc[i, j]\n",
    "#         if abs(v) >= threshold:\n",
    "#             high_pairs.append((cols[i], cols[j], float(v)))\n",
    "\n",
    "# # Save correlation matrix and high pairs\n",
    "# corr.to_csv(out_dir / 'correlation_matrix.csv')\n",
    "# with open(out_dir / 'high_corr_pairs.txt', 'w') as f:\n",
    "#     f.write(f'Pairs with |corr| >= {threshold}\\n')\n",
    "#     for a,b,v in high_pairs:\n",
    "#         f.write(f'{a}\\t{b}\\t{v:.4f}\\n')\n",
    "\n",
    "# # Prepare X for VIF: add constant not needed for VIF calculation\n",
    "# # Remove constant / zero-variance columns\n",
    "# stds = X_imp.std()\n",
    "# non_const = stds[stds > 0].index.tolist()\n",
    "# X_vif = X_imp[non_const]\n",
    "\n",
    "# # Standardize before computing condition number\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = pd.DataFrame(scaler.fit_transform(X_vif), index=X_vif.index, columns=X_vif.columns)\n",
    "\n",
    "# # Compute VIFs\n",
    "# vifs = []\n",
    "# for i, col in enumerate(X_vif.columns):\n",
    "#     try:\n",
    "#         vif_val = variance_inflation_factor(X_vif.values, i)\n",
    "#     except Exception as e:\n",
    "#         vif_val = np.nan\n",
    "#     vifs.append((col, float(vif_val)))\n",
    "\n",
    "# vif_df = pd.DataFrame(vifs, columns=['feature', 'VIF']).sort_values('VIF', ascending=False)\n",
    "# vif_df.to_csv(out_dir / 'vif.csv', index=False)\n",
    "\n",
    "# # Condition number (of X'X)\n",
    "# cond_number = np.linalg.cond(X_scaled)\n",
    "\n",
    "# # Compact printout\n",
    "# print('Multicollinearity check — compact summary')\n",
    "# print('-'*60)\n",
    "# print(f'Number of numeric features: {X_num.shape[1]}')\n",
    "# print(f'High-correlation pairs (|corr| >= {threshold}): {len(high_pairs)}')\n",
    "# for a,b,v in high_pairs[:10]:\n",
    "#     print(f'  {a} — {b}: {v:.3f}')\n",
    "# if len(high_pairs) > 10:\n",
    "#     print(f'  ... and {len(high_pairs)-10} more')\n",
    "\n",
    "# print('\\nTop VIFs:')\n",
    "# print(vif_df.head(10).to_string(index=False))\n",
    "# print(f'\\nCondition number (scaled X): {cond_number:.3f}')\n",
    "# print('\\nSaved:')\n",
    "# print(f' - correlation matrix -> {out_dir / \"correlation_matrix.csv\"}')\n",
    "# print(f' - high correlation pairs -> {out_dir / \"high_corr_pairs.txt\"}')\n",
    "# print(f' - VIFs -> {out_dir / \"vif.csv\"}')\n",
    "\n",
    "# # Expose variables for later inspection\n",
    "# _vif_df = vif_df\n",
    "# _high_corr_pairs = high_pairs\n",
    "# _cond_number = cond_number\n",
    "# _corr_matrix = corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43442d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for df_merge['log_sell_price_E']\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure column exists and drop NA values\n",
    "col = 'log_sell_price_E'\n",
    "if col not in df_merge.columns:\n",
    "    raise KeyError(f\"{col} not found in df_merge columns: {df_merge.columns.tolist()}\")\n",
    "\n",
    "data = df_merge[col].dropna()\n",
    "if data.shape[0] == 0:\n",
    "    print(f'No non-null values found for {col}')\n",
    "else:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.kdeplot(data, fill=True, bw_method='scott', color='C0')\n",
    "    plt.title('Density plot: log_sell_price_E', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('log_sell_price_E')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0c559",
   "metadata": {},
   "source": [
    "# Product E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f877099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_E.dropna(inplace=True)\n",
    "df_product_E['revenue_E'] = df_product_E['sell_price_E'] * df_product_E['sales_E']\n",
    "df_product_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a86cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_E = df_product_E['log_sell_price_E'].mode()\n",
    "print(type(mode_E))\n",
    "print(mode_E.iloc[0] )\n",
    "df_product_E['flag_discount_E'] = np.where(\n",
    "    df_product_E['log_sell_price_E'] < mode_E.iloc[0]*0.98, 1, 0\n",
    ")\n",
    "df_product_E['percentage_discount_E'] =  (mode_E.iloc[0] - df_product_E['log_sell_price_E']) / mode_E.iloc[0] * 100\n",
    "df_product_E['percentage_discount_E'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65319be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create continuous week column for df_product_E (based on elapsed time from earliest date)\n",
    "min_date = df_product_E.index.min()\n",
    "df_product_E['week'] = np.ceil((df_product_E.index - min_date).days / 7).astype(int)\n",
    "# Ensure week starts at 1 (not 0)\n",
    "df_product_E['week'] = df_product_E['week'] + 1\n",
    "print(f\"Week column created. Min date: {min_date}, Unique weeks: {sorted(df_product_E['week'].unique())}\")\n",
    "# print(df_product_E[['week']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e581a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['sell_price_E','sales_E','log_sales_E','log_sell_price_E','flag_discount_E','week']\n",
    "data = df_product_E[col_names].copy(deep=True)\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        'sell_price_E':'price','sales_E':'sales',\n",
    "        'log_sell_price_E':'ln_price','log_sales_E':'ln_sales'\n",
    "        }\n",
    "    )\n",
    "print(data.shape)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "# Fit log–log regression\n",
    "X = sm.add_constant(data['week'])\n",
    "model = sm.OLS(data['ln_sales'], X).fit()\n",
    "beta0, beta1 = model.params\n",
    "\n",
    "print(\"Regression coefficients:\")\n",
    "print(f\"β0 = {beta0:.4f}, β1 = {beta1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_weekend'] = (data['dayofweek'] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e4362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_statsmodels(fdf, target_column_name, independent_variables_columns):\n",
    "    \"\"\"\n",
    "    Perform OLS regression using statsmodels to predict log_sales_{product} from df_model.\n",
    "    \"\"\"\n",
    "    df_model = fdf[[target_column_name] + independent_variables_columns].copy(deep=True)\n",
    "    print(df_model.columns )\n",
    "    print(\"-\"*70)\n",
    "    print(df_model.columns.tolist())\n",
    "    # Use df_model\n",
    "    df_work = df_model.copy(deep=True)\n",
    "\n",
    "    target = target_column_name\n",
    "    if target not in df_work.columns:\n",
    "        raise KeyError(f\"{target} not found in df_model columns: {df_work.columns.tolist()}\")\n",
    "\n",
    "    # Select numeric features (exclude target)\n",
    "    X = df_work.select_dtypes(include=[\"number\"]).drop(columns=[target], errors='ignore')\n",
    "    y = df_work[target]\n",
    "\n",
    "    # Drop rows with NaNs\n",
    "    mask = X.notna().all(axis=1) & y.notna()\n",
    "    X = X.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "\n",
    "    # Remove constant columns\n",
    "    X = X.loc[:, X.std() > 0]\n",
    "\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Number of observations: {len(y)}\")\n",
    "    print(f\"Features ({len(X.columns)}): {X.columns.tolist()}\")\n",
    "\n",
    "    # Fit OLS\n",
    "    X_sm = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_sm)\n",
    "    results = model.fit()\n",
    "    beta0, beta1 = results.params[0], results.params[1]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STATSMODELS OLS REGRESSION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(results.summary())\n",
    "\n",
    "    # Store results\n",
    "    _sm_ols_results = results\n",
    "    \n",
    "    return _sm_ols_results, beta0, beta1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ba58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables_columns = ['week','percentage_discount_E']\n",
    "target_column_name = 'log_sales_E'\n",
    "linear_regression_statsmodels(df_product_E, target_column_name, independent_variables_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables_columns = ['week','flag_discount_E']\n",
    "target_column_name = 'log_sales_E'\n",
    "linear_regression_statsmodels(df_product_E, target_column_name, independent_variables_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables_columns = ['week','log_sell_price_E']\n",
    "target_column_name = 'log_sales_E'\n",
    "linear_regression_statsmodels(df_product_E, target_column_name, independent_variables_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_E.groupby('week')['sales_E'].sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164731a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_E.groupby('week')['sell_price_E'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_A['sell_price_A'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f96e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64027550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6a067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
